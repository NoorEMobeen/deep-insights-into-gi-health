{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe063d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from Validate import validate_net\n",
    "from Test import test_net\n",
    "from misc import print_metrics, training_curve \n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import logging\n",
    "import csv\n",
    "from torchvision import transforms, datasets, models\n",
    "import sklearn.metrics as mtc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Checking if GPU is used\n",
    "###########################\n",
    "\n",
    "use_cuda=torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device=torch.device(\"cuda:0\" if use_cuda else \"mps\" if use_mps else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346786b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "test_root_dir= \"path to your root directory\" # Example: \"../../Project/GastroVision22/test/\"\n",
    "model_evaluation_directory = \"Path to your all selected model directory\" # Example: \"../selected_models/\"\n",
    "greedy_soup_file = \"Name to your greedy soup result file\" # Example: \"greedy_soups_sorted_result_\" + str(batch_size)\n",
    "uniform_soup_file = \"Name to your uniform soup result file\" # Example: \"uniform_soups_sorted_result_\" + str(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Training\n",
    "####################################\n",
    "\n",
    "trans={\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "    \n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4762, 0.3054, 0.2368],\n",
    "                             [0.3345, 0.2407, 0.2164])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e99ff1",
   "metadata": {},
   "source": [
    "# Model Soups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f1344a",
   "metadata": {},
   "source": [
    "## Uniform Model Soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e33b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def uniform_soup(model, paths, device = \"cpu\", by_name = False):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model\n",
    "        \n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    for i, model_path in enumerate(paths):\n",
    "        if \".DS_Store\" in model_path: # only for Mac users\n",
    "            print(\"Cannot process \", model_path)\n",
    "            print(\"Continue...\")\n",
    "            continue\n",
    "        print(\"Loading: \", model_path)\n",
    "        checkpoint=torch.load(model_path,map_location=device)   # loading model\n",
    "        # change you dictionary name according to your saved model name\n",
    "        weight_dict = checkpoint['model_state_dict']\n",
    "        if by_name:\n",
    "            weight_dict = {k:v for k, v in weight_dict.items() if k in model_dict}\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying order of model paths\n",
    "model_names = os.listdir(model_evaluation_directory)\n",
    "# Add all your model weights in sorted order for greedy soup implementation\n",
    "model_names = [\"C_22_32.pth\", \"C_32_64.pth\", \"C_23_64.pth\", \"C_29_128.pth\", \"C_13_32.pth\", \"C_27_32.pth\", \"C_23_128.pth\", \"C_44_64.pth\", \"C_32_128.pth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#place all the model that are going to apply in model soup\n",
    "model_paths = []\n",
    "for name in model_names:\n",
    "    model_paths.append(model_evaluation_directory + name)\n",
    "    \n",
    "model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde62103",
   "metadata": {},
   "source": [
    "### Creating model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f72dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## recreating model\n",
    "n_classes=22  # number of classes used for training\n",
    "#Initialize model\n",
    "best_model = torchvision.models.densenet121(weights=True).to(device)   # make weights=True if you want to download pre-trained weights\n",
    "\n",
    "\n",
    "# Option to freeze model weights\n",
    "for param in best_model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "n_inputs = best_model.classifier.in_features\n",
    "best_model.classifier = nn.Sequential(\n",
    "              nn.Linear(n_inputs, n_classes),                  \n",
    "              nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7765855",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_model = uniform_soup(best_model, model_paths)\n",
    "uniform_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating testing data\n",
    "print('Generating test data')\n",
    "#Generators\n",
    "test_dataset= datasets.ImageFolder(test_root_dir,transform=trans['test'])\n",
    "test_generator=data.DataLoader(test_dataset,batch_size)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, filename):\n",
    "\n",
    "    ############################\n",
    "    #     Test uniform model\n",
    "    ############################\n",
    "    test_list=[]\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"Evaluating model\")\n",
    "    with torch.no_grad():\n",
    "           test_loss, test_metrics, test_num_steps=test_net(model,test_generator,device,criterion)\n",
    "\n",
    "    print_metrics(test_metrics,test_num_steps)\n",
    "    test_list.append(test_loss)\n",
    "\n",
    "\n",
    "    for k, vl in test_metrics.items():      \n",
    "        test_list.append(vl)              # append metrics results in a list\n",
    "\n",
    "    ##################################################################\n",
    "    # Writing test results to a csv file \n",
    "    ##################################################################\n",
    "\n",
    "    key_name=['Test_loss','Test_micro_precision','Test_micro_recall','Test_micro_f1','Test_macro_precision','Test_macro_recall','Test_macro_f1','Test_mcc']\n",
    "    try:\n",
    "\n",
    "            with open(filename+str('.csv'), 'a',newline=\"\") as f:\n",
    "                wr = csv.writer(f,delimiter=\",\")\n",
    "                wr.writerow(key_name)\n",
    "                zip(test_list)\n",
    "                wr.writerow(test_list) \n",
    "                wr.writerow(\"\") \n",
    "    except IOError:\n",
    "            print(\"I/O Error\")  \n",
    "            \n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98169394",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(uniform_model, uniform_soup_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a1314",
   "metadata": {},
   "source": [
    "## Greedy Soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    return ((y_true == y_pred.argmax(axis = -1)).sum() / len(y_true)).to(\"cpu\").item()\n",
    "\n",
    "def greedy_soup(model, path, data, metric, device = \"cpu\", update_greedy = False, compare = np.greater_equal, by_name = False, digits = 4, verbose = True, y_true = \"y_true\"):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model\n",
    "\n",
    "    if not isinstance(path, list):\n",
    "        path = [path]\n",
    "    score, soup = None, []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    model_dict = model.state_dict()\n",
    "    input_key = [key for key in inspect.getfullargspec(model.forward).args if key !=  \"self\"]\n",
    "    input_cnt = len(input_key)\n",
    "    for i, model_path in enumerate(path):\n",
    "        if \".DS_Store\" in model_path:\n",
    "            print(\"Cannot process \", model_path)\n",
    "            print(\"Continue...\")\n",
    "            continue\n",
    "        if update_greedy:\n",
    "            checkpoint=torch.load(model_path,map_location=device)   # loading model\n",
    "            weight_dict = checkpoint['model_state_dict']\n",
    "            if by_name:\n",
    "                weight_dict = {k:v for k, v in weight_dict.items() if k in model_dict}\n",
    "            if len(soup) != 0:\n",
    "                weight_dict = {key:(torch.sum(torch.stack([weight_dict[key], soup[key]]), axis = 0) / 2).type(weight_dict[key].dtype)  for key in model_dict.keys()}\n",
    "            model_dict.update(weight_dict)\n",
    "            model.load_state_dict(model_dict)\n",
    "        else:\n",
    "            model = uniform_soup(model, soup + [model_path], device = device, by_name = by_name)\n",
    "                \n",
    "        iterator = iter(data)\n",
    "        history = []\n",
    "        step = 0\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                text = \"\"\n",
    "                iter_data = next(iterator)\n",
    "                if not isinstance(iter_data, dict):\n",
    "                    x = iter_data[:input_cnt]\n",
    "                    y = list(iter_data[input_cnt:])\n",
    "                    y = [d.to(device) if isinstance(d, torch.Tensor) else d for d in y]\n",
    "                    d_cnt = len(y[0])\n",
    "                else:\n",
    "                    x = [iter_data[k] for k in input_key if k in iter_data]\n",
    "                x = [d.to(device) if isinstance(d, torch.Tensor) else d for d in x]\n",
    "                step += 1\n",
    "                #del x\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    logits = model(*x)\n",
    "                    if isinstance(logits, torch.Tensor):\n",
    "                        logits = [logits]\n",
    "                        \n",
    "                    if isinstance(iter_data, dict):\n",
    "                        metric_key = [key for key in inspect.getfullargspec(func).args if key !=  \"self\"]\n",
    "                        if len(metric_key) == 0:\n",
    "                            metric_key = [y_true]\n",
    "                        y = [iter_data[k] for k in metric_key if k in iter_data]\n",
    "                        y = [d.to(device) if isinstance(d, torch.Tensor) else d for d in y]\n",
    "                        d_cnt = len(y[0])\n",
    "                    metric_val = np.array(metric(*(y + logits)))\n",
    "                    if np.ndim(metric_val) == 0:\n",
    "                        metric_val = [float(metric_val)] * d_cnt\n",
    "                    history += list(metric_val)\n",
    "                    #del y, logits\n",
    "\n",
    "                if verbose:\n",
    "                    sys.stdout.write(\"\\r[{name}] step: {step} - time: {time:.2f}s - {key}: {val:.{digits}f}\".format(name = os.path.basename(model_path), step = step, time = (time.time() - start_time), key = metric.__name__ if hasattr(metric, \"__name__\") else str(metric), val = np.nanmean(history), digits = digits))\n",
    "                    sys.stdout.flush()\n",
    "            except StopIteration:\n",
    "                print(\"\")\n",
    "                #gc.collect()\n",
    "                break\n",
    "        if 0 < len(history) and (score is None or compare(np.nanmean(history), score)):\n",
    "            score = np.nanmean(history)\n",
    "            if update_greedy:\n",
    "                soup = weight_dict\n",
    "            else:\n",
    "                soup += [model_path]\n",
    "    if len(soup) != 0:\n",
    "        if update_greedy:\n",
    "            model_dict.update(soup)\n",
    "            model.load_state_dict(model_dict)\n",
    "        else:\n",
    "            model = uniform_soup(model, soup, device = device, by_name = by_name)\n",
    "        if verbose:\n",
    "            print(\"greedy soup best score : {val:.{digits}f}\".format(val = score, digits = digits))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d551cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_model = greedy_soup(model=best_model, path=model_paths, data=test_generator, metric=metric, device = \"cpu\", update_greedy = False, compare = np.greater_equal, by_name = False, digits = 4, verbose = True, y_true = \"y_true\")\n",
    "\n",
    "greedy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0231d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(greedy_model, greedy_soup_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad55fa",
   "metadata": {},
   "source": [
    "### Greedy Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_model_update = greedy_soup(model=best_model, path=model_paths, data=test_generator, metric=metric, device = \"cpu\", update_greedy = True, compare = np.greater_equal, by_name = False, digits = 4, verbose = True, y_true = \"y_true\")\n",
    "\n",
    "greedy_model_update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
